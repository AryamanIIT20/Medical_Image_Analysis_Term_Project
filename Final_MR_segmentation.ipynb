{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ad630-84a8-4384-8050-ca1283da620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from timeit import default_timer as timer\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import cv2\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "%config InlineBackend.figure_format = \"svg\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(f\"Using device:{device}\")\n",
    "print(f\"Using {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b9ce79-a9ad-49b8-b2fd-232f6a2eb63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomMRTestDataset(Dataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.image_paths = self._get_image_paths()\n",
    "\n",
    "#     def _get_image_paths(self):\n",
    "#         image_paths = []\n",
    "#         for file_name in os.listdir(self.root_dir):\n",
    "#             if file_name.endswith('.jpeg'):\n",
    "#                 image_paths.append(os.path.join(self.root_dir, file_name))\n",
    "#         return image_paths\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.image_paths[idx]\n",
    "#         image = Image.open(img_path).convert(\"L\")  # Ensure that images are RGB (not grayscale)\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "\n",
    "# # Define data transformations\n",
    "# transform = transforms.Compose([\n",
    "#     # transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # Create custom dataset\n",
    "# test_dataset = CustomMRTestDataset(root_dir='MR_test', transform=transform)\n",
    "# len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_values(img):\n",
    "    new_img = torch.zeros_like(img)\n",
    "    new_img[(img >= 55) & (img <= 70)] = 1\n",
    "    new_img[(img >= 110) & (img <= 135)] = 2\n",
    "    new_img[(img >= 175) & (img <= 200)] = 3\n",
    "    new_img[(img >= 240) & (img <= 255)] = 4\n",
    "    return new_img.type(torch.uint8)\n",
    "\n",
    "class CustomMRDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpeg')]\n",
    "        self.label_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.image_files.sort()\n",
    "        self.label_files.sort()\n",
    "        assert len(self.image_files) == len(self.label_files), \"Number of images and labels must match\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        label_name = os.path.join(self.root_dir, self.label_files[idx])\n",
    "        \n",
    "        # Load image and label\n",
    "        image = Image.open(img_name).convert(\"L\")\n",
    "        label = Image.open(label_name).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "            label = (label*255).type(torch.uint8)\n",
    "            label = reassign_values(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Example usage:\n",
    "# Define transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Create custom dataset\n",
    "custom_dataset = CustomMRDataset(root_dir=\"MR_train\", transform=transform)\n",
    "class_names = {0:\"background\",1:\"liver\",2:\"right kidney\",3:\"left kidney\",4:\"spleen\"}\n",
    "\n",
    "train_size = int(0.9 * len(custom_dataset))  # 80% of the data for training\n",
    "val_size = len(custom_dataset) - train_size  # Remaining 20% for validation\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n",
    "\n",
    "# Print the number of samples in the train dataset\n",
    "print(\"Number of samples in the train dataset:\", len(train_dataset))\n",
    "print(\"Number of samples in the validation dataset:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae3541-2ac7-412a-82f6-f2118f012a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = torch.randint(0, len(train_dataset), size = [1,]).item()\n",
    "colors = colors = ['black', 'blue', 'green', 'yellow', 'red']\n",
    "cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "img,mask = train_dataset[random_idx]\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img.squeeze(), cmap = \"gray\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask.squeeze(), cmap = cmap)\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "img.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fa4a4-2395-4ed4-8a6f-7132f350c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d7832-5e45-45a2-a9b5-06dd23a27d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41cd57f-fd6b-4d94-97b1-237d2cf4a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scSE(nn.Module):\n",
    "    def __init__(self, in_channels, r = 2):\n",
    "        super(scSE, self).__init__()\n",
    "        mid_channels = in_channels//r\n",
    "        self.cSE = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(mid_channels, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sSE = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Take mean over H and W dimensions\n",
    "        mean_tensor = torch.mean(x, dim=[2, 3], keepdim=True)\n",
    "        channel_scaling = self.cSE(mean_tensor).expand(-1, -1, x.size(2), x.size(3))\n",
    "        u_cSE = x*channel_scaling\n",
    "        spatial_scaling = self.sSE(x).expand(-1, x.size(1), -1, -1)\n",
    "        u_sSE = x*spatial_scaling\n",
    "        return torch.maximum(u_sSE,u_cSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989be444-c205-4d2c-96a4-3f86dca5c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        # self.SE1 = scSE(16)\n",
    "        # self.SE2 = scSE(32)\n",
    "        # self.SE3 = scSE(64)\n",
    "        # self.SE4 = scSE(128)\n",
    "        # self.SE5 = scSE(64)\n",
    "        # self.SE6 = scSE(32)\n",
    "        # self.SE7 = scSE(16)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x1 = self.SE1(self.inc(x))\n",
    "        # x2 = self.SE2(self.down1(x1))\n",
    "        # x3 = self.SE3(self.down2(x2))\n",
    "        # x4 = self.SE4(self.down3(x3))\n",
    "        # x5 = self.down4(x4)\n",
    "        # x = self.SE5(self.up1(x5, x4))\n",
    "        # x = self.SE6(self.up2(x, x3))\n",
    "        # x = self.SE7(self.up3(x, x2))\n",
    "\n",
    "        x1 = (self.inc(x))\n",
    "        x2 = (self.down1(x1))\n",
    "        x3 = (self.down2(x2))\n",
    "        x4 = (self.down3(x3))\n",
    "        x5 = self.down4(x4)\n",
    "        x = (self.up1(x5, x4))\n",
    "        x = (self.up2(x, x3))\n",
    "        x = (self.up3(x, x2))\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(SEUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.SE1 = scSE(16)\n",
    "        self.SE2 = scSE(32)\n",
    "        self.SE3 = scSE(64)\n",
    "        self.SE4 = scSE(128)\n",
    "        self.SE5 = scSE(64)\n",
    "        self.SE6 = scSE(32)\n",
    "        self.SE7 = scSE(16)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(128, 256 // factor)\n",
    "        self.up1 = Up(256, 128 // factor, bilinear)\n",
    "        self.up2 = Up(128, 64 // factor, bilinear)\n",
    "        self.up3 = Up(64, 32 // factor, bilinear)\n",
    "        self.up4 = Up(32, 16, bilinear)\n",
    "        self.outc = OutConv(16, self.n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.SE1(self.inc(x))\n",
    "        x2 = self.SE2(self.down1(x1))\n",
    "        x3 = self.SE3(self.down2(x2))\n",
    "        x4 = self.SE4(self.down3(x3))\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.SE5(self.up1(x5, x4))\n",
    "        x = self.SE6(self.up2(x, x3))\n",
    "        x = self.SE7(self.up3(x, x2))\n",
    "\n",
    "        # x1 = (self.inc(x))\n",
    "        # x2 = (self.down1(x1))\n",
    "        # x3 = (self.down2(x2))\n",
    "        # x4 = (self.down3(x3))\n",
    "        # x5 = self.down4(x4)\n",
    "        # x = (self.up1(x5, x4))\n",
    "        # x = (self.up2(x, x3))\n",
    "        # x = (self.up3(x, x2))\n",
    "        \n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a86d79-7d37-4615-8282-0a26d4bbcfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "n_classes = 5\n",
    "# model = SegNet(in_chn = 1, out_chn = 5).to(device)\n",
    "model = SEUNet(n_channels = n_channels, n_classes = n_classes, bilinear = True)\n",
    "#model = UNet(n_channels = n_channels, n_classes = n_classes)\n",
    "summary(model, input_size = [8,1,512,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ba7d0-89d8-4ac4-82e5-3b56665ad603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_class_weights(dataset):\n",
    "#     # Initialize counters for each class\n",
    "#     class_counts = {0:0,1:0,2:0,3:0,4:0}\n",
    "    \n",
    "#     # Iterate through the dataset to count pixel occurrences\n",
    "#     for _, labels in tqdm(dataset):\n",
    "#         # Flatten the label tensor and count occurrences\n",
    "#         unique, counts = torch.unique(labels, return_counts=True)\n",
    "#         for i,value in enumerate(unique):\n",
    "#             class_counts[value.item()] +=counts[i]\n",
    "    \n",
    "#     # Calculate inverse frequencies\n",
    "#     class_freq = np.zeros((5,))\n",
    "#     total = 0\n",
    "#     for i in range(5):\n",
    "#         class_freq[i] = class_counts[i]\n",
    "#         total = total + class_counts[i]\n",
    "        \n",
    "#     class_weights = total/class_freq\n",
    "#     class_weights = class_weights/torch.sum(class_weights)\n",
    "\n",
    "#     return class_weights.float()\n",
    "\n",
    "# # Example usage:\n",
    "# class_weights = calculate_class_weights(train_dataset)\n",
    "# print(\"Class Weights:\", class_weights)\n",
    "# class_weights = class_weights.to(device)\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9845d6d-1d8a-410f-9961-e393c5dfa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_coefficient(prediction, target, class_index):\n",
    "    smooth = 1e-7\n",
    "    prediction = prediction == class_index\n",
    "    target = target == class_index\n",
    "\n",
    "    intersection = torch.sum(prediction & target).item()\n",
    "    union = torch.sum(prediction | target).item()\n",
    "\n",
    "    jaccard_score = (intersection + smooth) / (union + smooth)\n",
    "    return jaccard_score\n",
    "\n",
    "def compute_average_jaccard_coefficient(model, dataset, num_classes):\n",
    "    model.eval()\n",
    "    class_jaccard_scores = np.zeros(num_classes)\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in tqdm(dataset):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs.unsqueeze(0)).squeeze().argmax(dim = 0)\n",
    "\n",
    "            for class_index in range(num_classes):\n",
    "                class_jaccard_scores[class_index] += jaccard_coefficient(outputs, targets, class_index)\n",
    "\n",
    "    average_jaccard_scores = class_jaccard_scores / len(dataset)\n",
    "    return average_jaccard_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96f369-d475-413b-bf8b-9d05105f366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight=None):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        # Reshape logits to [batch_size * height * width, num_classes]\n",
    "        logits_flat = logits.permute(0, 2, 3, 1).contiguous().view(-1, logits.shape[1])\n",
    "        \n",
    "        # Reshape labels to [batch_size * height * width]\n",
    "        labels_flat = labels.view(-1)\n",
    "\n",
    "        # Calculate cross entropy loss\n",
    "        if self.weight is not None:\n",
    "            # Apply class weights if provided\n",
    "            loss = F.cross_entropy(logits_flat, labels_flat, weight=self.weight)\n",
    "        else:\n",
    "            # Without class weights\n",
    "            loss = F.cross_entropy(logits_flat, labels_flat)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1e445-29fe-4914-b57c-06293da659c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyDiceLoss(nn.Module):\n",
    "    def __init__(self, num_classes, weight_ce=None, smooth_dice=1.):\n",
    "        super(CrossEntropyDiceLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.weight_ce = weight_ce\n",
    "        self.smooth_dice = smooth_dice\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Reshape logits to [N*H*W, C] and targets to [N*H*W]\n",
    "        logits = logits.permute(0, 2, 3, 1).contiguous().view(-1, self.num_classes)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Cross-entropy loss\n",
    "        ce_loss = F.cross_entropy(logits, targets, weight=self.weight_ce)\n",
    "\n",
    "        # Reshape logits back to [N, H, W, C]\n",
    "        logits = logits.view(-1, logits.size(-1)).view(logits.size(0), -1, logits.size(-1)).permute(0, 2, 1)\n",
    "\n",
    "        # Dice loss\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        dice_loss = 0.\n",
    "\n",
    "        for class_idx in range(1, self.num_classes):  # Exclude background class\n",
    "            class_probs = probs[:, class_idx]\n",
    "            class_targets = (targets == class_idx).float()\n",
    "\n",
    "            # Flatten probabilities and targets\n",
    "            class_probs_flat = class_probs.view(-1)\n",
    "            class_targets_flat = class_targets.view(-1)\n",
    "\n",
    "            # Calculate intersection and union\n",
    "            intersection = torch.sum(class_probs_flat * class_targets_flat)\n",
    "            union = torch.sum(class_probs_flat) + torch.sum(class_targets_flat)\n",
    "\n",
    "            # Calculate Dice coefficient\n",
    "            dice_coefficient = (2. * intersection + self.smooth_dice) / (union + self.smooth_dice)\n",
    "\n",
    "            # Add class Dice loss to the total loss\n",
    "            dice_loss += 1. - dice_coefficient\n",
    "\n",
    "        # Average over classes\n",
    "        dice_loss /= (self.num_classes - 1)\n",
    "\n",
    "        # Combine cross-entropy and Dice losses\n",
    "        loss = ce_loss + dice_loss\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b81da-01ff-4e5f-b445-6d4e4bc17a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = torch.randint(0, len(train_dataset), size = [1,]).item()\n",
    "image,mask = train_dataset[random_idx]\n",
    "image = image.to(device)\n",
    "pred = model(image.unsqueeze(dim = 0)).squeeze()\n",
    "labels = pred.squeeze().argmax(dim = 0).detach()\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(labels.cpu(), cmap = \"jet\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask.squeeze(), cmap = \"jet\")\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870330d-b752-4bc2-8e72-fead88b0862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start, end, device=None):\n",
    "    total_time = end - start\n",
    "    print(f\"\\nTrain time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d2d2d1-aa0d-4618-84b0-c166556f7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 1\n",
    "n_classes = 5\n",
    "model = SEUNet(n_channels,n_classes, bilinear = True).to(device)\n",
    "# model = nn.DataParallel(model)\n",
    "# model = SESegNet(in_chn = 1,out_chn = 5).to(device)\n",
    "class_weights = torch.tensor([0.05,0.05,0.3,0.3,0.3]).to(device)\n",
    "loss_fn = CrossEntropyDiceLoss(num_classes = n_classes, weight_ce = None)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 4, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f19a9-34bd-4862-8f9b-a13e29489e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "\n",
    "initialize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dcbf3-d9a2-461d-bdc2-f3e92cc69161",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 7\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n",
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f881907-096f-443d-bd97-72123debe0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "train_start = timer()\n",
    "train_loss_vec = []\n",
    "val_loss_vec = []\n",
    "epoch_vec = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print(f\"Epoch {epoch}\\n-----------\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i,(img,mask) in enumerate(train_dataloader):\n",
    "        if i%10 == 0:\n",
    "            print(f\"Train Mini-batch {i}\")\n",
    "        img,mask = img.to(device), mask.long().to(device)\n",
    "        pred = model(img)\n",
    "        loss = loss_fn(pred,mask.squeeze())\n",
    "        train_loss+=loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss/=len(train_dataloader)\n",
    "    train_loss_vec.append(train_loss.detach().cpu())\n",
    "    epoch_vec.append(epoch)\n",
    "    \n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for i,(val_img, val_mask) in enumerate(val_dataloader):\n",
    "            if i%10==0:\n",
    "                print(f\"Validation Mini-batch {i}\")\n",
    "            val_img,val_mask = val_img.to(device), val_mask.long().to(device)\n",
    "            val_pred = model(val_img)\n",
    "            val_loss_step = loss_fn(val_pred,val_mask.squeeze())\n",
    "            val_loss += val_loss_step\n",
    "                \n",
    "        val_loss/=len(val_dataloader)\n",
    "        val_loss_vec.append(val_loss.cpu())\n",
    "\n",
    "    # scheduler.step()\n",
    "    print(f\"Training Loss = {train_loss:.4f} | Validation Loss = {val_loss:.4f}\")\n",
    "\n",
    "train_stop = timer()\n",
    "time_taken = print_train_time(train_start, train_stop, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08dfd45-6472-422b-b253-867abf8bbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = torch.randint(0, len(train_dataset), size = [1,]).item()\n",
    "image,mask = train_dataset[random_idx]\n",
    "image = image.to(device)\n",
    "pred = model(image.unsqueeze(dim = 0)).squeeze()\n",
    "labels = pred.squeeze().argmax(dim = 0).detach()\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(labels.cpu(), cmap = \"jet\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask.squeeze(), cmap = \"jet\")\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92707e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss_curves(train_loss_vec,val_loss_vec,epoch_vec):\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_vec,label = \"training loss\")\n",
    "    plt.plot(val_loss_vec,label = \"validation loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_curves(train_loss_vec,val_loss_vec,epoch_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cf0be-c095-40ad-977b-42ead9f52189",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "jaccard_scores = compute_average_jaccard_coefficient(model, train_dataset, num_classes)\n",
    "print(jaccard_scores)\n",
    "jaccard_avg = np.mean(jaccard_scores[1:])\n",
    "print(jaccard_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba199d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "MODEL_NAME = \"mr_unet.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
    "# torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_se_model = UNet(n_channels = 1,n_classes = 5,bilinear = True).to(device)\n",
    "# non_se_model = SegNet(in_chn = 1,out_chn = 5).to(device)\n",
    "non_se_model.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11837d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "MODEL_NAME = \"mr_seunet.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
    "# torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_model = SEUNet(n_channels = 1,n_classes = 5,bilinear = True).to(device)\n",
    "# se_model = SESegNet(in_chn = 1,out_chn = 5).to(device)\n",
    "se_model.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78650dc1-3bc4-4e36-bfab-a3da6434016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravd_coefficient(prediction, target, class_index):\n",
    "    smooth = 1e-7\n",
    "    prediction = prediction == class_index\n",
    "    target = target == class_index\n",
    "\n",
    "    v_seg = torch.sum(prediction).item()\n",
    "    v_ref = torch.sum(target).item()\n",
    "    if v_ref == 0:\n",
    "        return 0\n",
    "    ravd_score = 100*(np.abs(v_seg-v_ref))/(v_ref)\n",
    "    return ravd_score\n",
    "\n",
    "def compute_average_ravd_coefficient(model, dataset, num_classes):\n",
    "    model.eval()\n",
    "    class_ravd_scores = np.zeros(num_classes)\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in tqdm(dataset):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs.unsqueeze(0)).squeeze().argmax(dim = 0)\n",
    "\n",
    "            for class_index in range(num_classes):\n",
    "                class_ravd_scores[class_index] += ravd_coefficient(outputs, targets, class_index)\n",
    "\n",
    "    average_ravd_scores = class_ravd_scores / len(dataset)\n",
    "    return average_ravd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f19b7-4d19-4de8-b606-7f99b542993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(prediction, target, class_index):\n",
    "    smooth = 1e-7\n",
    "    prediction = prediction == class_index\n",
    "    target = target == class_index\n",
    "\n",
    "    intersection = torch.sum(prediction & target).item()\n",
    "    union = torch.sum(prediction).item() + torch.sum(target).item()\n",
    "\n",
    "    dice_score = (2*intersection + smooth) / (union + smooth)\n",
    "    return dice_score\n",
    "\n",
    "def compute_average_dice_coefficient(model, dataset, num_classes):\n",
    "    model.eval()\n",
    "    class_dice_scores = np.zeros(num_classes)\n",
    "    with torch.inference_mode():\n",
    "        for inputs, targets in tqdm(dataset):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs.unsqueeze(0)).squeeze().argmax(dim = 0)\n",
    "\n",
    "            for class_index in range(num_classes):\n",
    "                class_dice_scores[class_index] += dice_coefficient(outputs, targets, class_index)\n",
    "\n",
    "    average_dice_scores = class_dice_scores / len(dataset)\n",
    "    return average_dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e7b0e-2b53-4bd6-b949-b1295b1be388",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "se_jaccard_scores = compute_average_jaccard_coefficient(se_model, val_dataset, num_classes)\n",
    "print(se_jaccard_scores)\n",
    "se_jaccard_avg = np.mean(se_jaccard_scores[1:])\n",
    "print(se_jaccard_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38b2a9-4fd8-430d-9490-ac0488d1d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "non_se_jaccard_scores = compute_average_jaccard_coefficient(non_se_model, val_dataset, num_classes)\n",
    "print(non_se_jaccard_scores)\n",
    "non_se_jaccard_avg = np.mean(non_se_jaccard_scores[1:])\n",
    "print(non_se_jaccard_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01a563-19b9-421b-93d8-32e59a3b547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "se_dice_scores = compute_average_dice_coefficient(se_model, val_dataset, num_classes)\n",
    "print(se_dice_scores)\n",
    "se_dice_avg = np.mean(se_dice_scores[1:])\n",
    "print(se_dice_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d2f9d-135d-4047-9878-5152c09f68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "non_se_dice_scores = compute_average_dice_coefficient(non_se_model, val_dataset, num_classes)\n",
    "print(non_se_dice_scores)\n",
    "non_se_dice_avg = np.mean(non_se_dice_scores[1:])\n",
    "print(non_se_dice_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdece7c6-db3c-4e59-a2f5-99945f71d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "se_ravd_scores = compute_average_ravd_coefficient(se_model, val_dataset, num_classes)\n",
    "print(se_ravd_scores)\n",
    "se_ravd_avg = np.mean(se_ravd_scores[1:])\n",
    "print(se_ravd_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d54e76-e0ec-4745-bd73-ae3f37e1a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "non_se_ravd_scores = compute_average_ravd_coefficient(non_se_model, val_dataset, num_classes)\n",
    "print(non_se_ravd_scores)\n",
    "non_se_ravd_avg = np.mean(non_se_ravd_scores[1:])\n",
    "print(non_se_ravd_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecaeea-5b3e-4c16-bafc-4cfe7fff6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d737170-adda-42b5-9a6f-3c420010786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_idx = torch.randint(0, len(train_dataset), size = [1,]).item()\n",
    "image,mask = train_dataset[random_idx]\n",
    "image = image.to(device)\n",
    "pred_non_se = non_se_model(image.unsqueeze(dim = 0)).squeeze()\n",
    "pred_se = se_model(image.unsqueeze(dim = 0)).squeeze()\n",
    "labels_non_se = pred_non_se.squeeze().argmax(dim = 0).detach()\n",
    "labels_se = pred_se.squeeze().argmax(dim = 0).detach()\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(image.squeeze().to(\"cpu\"), cmap = \"gray\")\n",
    "plt.title(\"Input\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(labels_non_se.cpu(), cmap = cmap)\n",
    "plt.title(\"Non SE\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(labels_se.cpu(), cmap = cmap)\n",
    "plt.title(\"SE\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(mask.squeeze(), cmap = cmap)\n",
    "plt.title(\"GT\")\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "random_idx+=1\n",
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2d219-2a5c-4afe-befa-0c99dfedccb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
